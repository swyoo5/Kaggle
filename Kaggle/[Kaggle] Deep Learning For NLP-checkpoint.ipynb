{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b7cf4fd",
   "metadata": {},
   "source": [
    "출처 : https://www.kaggle.com/code/tanulsingh077/deep-learning-for-nlp-zero-to-transformers-bert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b24c91f",
   "metadata": {},
   "source": [
    "# Jigsaw Multilingual Toxic Comment Classification\n",
    "## 데이터 설명\n",
    "[데이터 링크](https://www.kaggle.com/competitions/jigsaw-multilingual-toxic-comment-classification/data)\n",
    "\n",
    "데이터의 제목은 \"Jigsaw 다국어 악성 댓글 분류\"라는 뜻이다. 각각의 제공된 파일에는 comment_text라는 열이 있다. 이는 악성인지 악성이 아닌지로 분류되는 댓글의 텍스트를 포함한다(toxic열에 0, 1이 있다). 훈련 셋의 댓글들은 모두 영어로 이루어져 있고 Civil Comments 또는 Wikipedia talk page egits로부터 왔다. 테스트 데이터의 comment_text 열에는 영어가 아닌 다국어로 이루어져 있다.\n",
    "\n",
    "train.csv 파일과 **validation.csv** 파일은 또한 훈련되어야 하는 타겟인 toxic 열이 포함되어있다.\n",
    "\n",
    "**jigsaw-toxic-comment-train.csv**와 **jigsaw-unintended-bias-train.csv**는 두개의 이전 jigsaw competitions로부터 온 훈련 데이터(comment-text, toxic)가 포함되어있고 뿐만 아니라 유용한 추가적인 열도 포함되어있다.\n",
    "\n",
    "*seqlen128.csv* 파일은 BERT에 입력으로 처리될 훈련, 검증, 테스트 데이터를 포함한다.\n",
    "\n",
    "## 무엇을 예측하는가?\n",
    "당신은 댓글이 악성일 확률을 예측한다. 악성 댓글은 1.0을 받는다. 온순하고 악성이 아닌 댓글은 0.0을 받는다. 테스트 셋에서 모든 댓글들은 1.0 또는 0.0을 받는다.\n",
    "\n",
    "## 파일들\n",
    "* jigsaw-toxic-comment-train.csv : 우리의 첫번째 대회의 데이터이다. 이 데이터는 위키피디아 토크 페이지로부터 온 영어 댓글로 만들어져있다.\n",
    "* jigsaw-unintended-bias-train.csv : 두번째 대회의 데이터이다. 이는 추가적인 라벨이 붙은 Civil Comments 데이터셋의 확장된 버전이다.\n",
    "* sample_submission.csv : 올바른 형식의 샘플 제출 파일\n",
    "* test.csv : 영어가 아닌 언어로 이루어진 위키피디아 토크 페이지의 댓글들이다.\n",
    "* test_labels.csv : 테스트 데이터의 정답 라벨(대회 데드라인 이후에 추가된 데이터)\n",
    "* validation.csv : 영어가 아닌 언어로 이루어진 위키피디아 토크 페이지의 댓글들\n",
    "* jigsaw-toxic-comment-train-processed-seqlen128.csv : BERT를 위해 전처리된 훈련 데이터\n",
    "* jigsaw-unintended-bias-train-processed-seqlen128.csv : BERT를 위해 전처리된 훈련 데이터\n",
    "* validation-processed-seqlen128.csv : BERT를 위해 전처리된 검증용 데이터\n",
    "* test-processed-seqlen128.csv : BERT를 위해 전처리된 테스트 데이터\n",
    "\n",
    "## 열(columns)\n",
    "* id : 각 파일의 식별자\n",
    "* comment_text : 분류되어야 하는 댓글의 텍스트\n",
    "* lang : 댓글의 언어\n",
    "* toxic : 댓글이 악성인지 아닌지로 분류(**text.csv**에는 없다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c9170bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, GRU, SimpleRNN, Dense, Activation, Dropout, Embedding, BatchNormalization, GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
    "from tensorflow.keras.preprocessing import sequence, text\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from plotly import graph_objs as go\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fba98fc",
   "metadata": {},
   "source": [
    "## TPU 구성\n",
    "이 노트북의 버전에서 우리는 BERT 모델을 만들어야 하기 때문에 TPU를 사용할 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12ebb33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPLICAS :  1\n"
     ]
    }
   ],
   "source": [
    "try :\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print(\"Running on TPU \", tpu.master())\n",
    "except ValueError :\n",
    "    tpu = None\n",
    "    \n",
    "if tpu : \n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else :\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "    \n",
    "print(\"REPLICAS : \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16297894",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('C:/Users/User/자연어처리/Kaggle/jigsaw-multilingual-toxic-comment-classification/jigsaw-toxic-comment-train.csv')\n",
    "validation = pd.read_csv('C:/Users/User/자연어처리/Kaggle/jigsaw-multilingual-toxic-comment-classification/validation.csv')\n",
    "test = pd.read_csv('C:/Users/User/자연어처리/Kaggle/jigsaw-multilingual-toxic-comment-classification/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c9dfcfd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df39dbc1",
   "metadata": {},
   "source": [
    "우리는 다른 열들을 제거할 것이고 이 문제를 이진 분류 문제로 접근할 것이다. 또한 우리는 모델을 더 쉽게 훈련할 수 있도록 데이터셋의 더 작은 하위 섹션(12000개 데이터 포인트)에 대해 훈련을 수행할 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d8672588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(223549, 8)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "438791ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop([\"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2f33bbbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12001, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.loc[:12000, : ]\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b937607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11996</th>\n",
       "      <td>1fc25487b9b9187f</td>\n",
       "      <td>February 2006 (UTC)\\n\\nThank you for fixing th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11997</th>\n",
       "      <td>1fc3e5540e2605d1</td>\n",
       "      <td>Erased another silly message.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11998</th>\n",
       "      <td>1fc4c99c34cf0e07</td>\n",
       "      <td>\"\\n\\n Helly Jimmy, well; fuck you. \\n\\nAccordi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999</th>\n",
       "      <td>1fc8d9f16da8cccc</td>\n",
       "      <td>Why don't you run cry to your mommy, little As...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12000</th>\n",
       "      <td>1fc9441f74fb9440</td>\n",
       "      <td>\"\\n\\nThat is not a list of official names of o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12001 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                                       comment_text  \\\n",
       "0      0000997932d777bf  Explanation\\nWhy the edits made under my usern...   \n",
       "1      000103f0d9cfb60f  D'aww! He matches this background colour I'm s...   \n",
       "2      000113f07ec002fd  Hey man, I'm really not trying to edit war. It...   \n",
       "3      0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...   \n",
       "4      0001d958c54c6e35  You, sir, are my hero. Any chance you remember...   \n",
       "...                 ...                                                ...   \n",
       "11996  1fc25487b9b9187f  February 2006 (UTC)\\n\\nThank you for fixing th...   \n",
       "11997  1fc3e5540e2605d1                      Erased another silly message.   \n",
       "11998  1fc4c99c34cf0e07  \"\\n\\n Helly Jimmy, well; fuck you. \\n\\nAccordi...   \n",
       "11999  1fc8d9f16da8cccc  Why don't you run cry to your mommy, little As...   \n",
       "12000  1fc9441f74fb9440  \"\\n\\nThat is not a list of official names of o...   \n",
       "\n",
       "       toxic  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "...      ...  \n",
       "11996      0  \n",
       "11997      0  \n",
       "11998      1  \n",
       "11999      1  \n",
       "12000      0  \n",
       "\n",
       "[12001 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafe0053",
   "metadata": {},
   "source": [
    "댓글에서 표현될 수 있는 최대의 단어 갯수를 체크한다. 이는 나중에 패딩을 할 때 도움을 줄 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "78dc0e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1403"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 댓글의 최대 길이\n",
    "train[\"comment_text\"].apply(lambda x : len(str(x).split())).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e5827a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_auc(predictions, target) :\n",
    "    '''\n",
    "    이 메서드는 예측값들과 라벨들이 주어졌을 때 AUC Score를 반환한다.\n",
    "    '''\n",
    "    \n",
    "    fpr, tpr, thresholds = metrics.roc_curve(target, predictions)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c37ae8",
   "metadata": {},
   "source": [
    "## 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "169752e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xvalid, ytrain, yvalid = train_test_split(train.comment_text.values, train.toxic.values, stratify = train.toxic.values, random_state = 42, test_size = 0.2, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc82463f",
   "metadata": {},
   "source": [
    "## Simple RNN\n",
    "### 기본 개요\n",
    "RNN은 이전 시점의 출력이 현재 시점의 입력으로 들어오는 신경망이다. 전통적인 신경망은 모든 입력과 출력이 각각 독립적이지만 문장의 다음 단어를 예측하기 위해 필요한 경우처럼 이전 단어는 필요하고 이런 이유로 이전 단어를 기억할 필요가 있다. 그래서 은닉층을 이용해 이 문제점을 해결한 RNN이 나타났다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1c338ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = text.Tokenizer(num_words = None)\n",
    "max_len = 1500\n",
    "\n",
    "# 주어진 텍스트 데이터 이용하여 토크나이저 학습\n",
    "# 이를 수행하고 나면 단어-인덱스 매핑이 word_index에 저장된다.\n",
    "token.fit_on_texts(list(xtrain) + list(xvalid))\n",
    "# 주어진 텍스트에 대해서 정수 인덱스를 할당해 변환한다.\n",
    "xtrain_seq = token.texts_to_sequences(xtrain)\n",
    "xvalid_seq = token.texts_to_sequences(xvalid)\n",
    "\n",
    "xtrain_pad = sequence.pad_sequences(xtrain_seq, maxlen = max_len)\n",
    "xvalid_pad = sequence.pad_sequences(xvalid_seq, maxlen = max_len)\n",
    "\n",
    "word_index = token.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "976caa1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 1500, 300)         13049100  \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (None, 100)               40100     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 13,089,301\n",
      "Trainable params: 13,089,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Wall time: 779 ms\n"
     ]
    }
   ],
   "source": [
    "# 주피터 노트북에서 사용되는 매직 명령어 중 하나로 이를 사용하면 코드 셀의 실행 시간을 측정할 수 있다.\n",
    "%%time\n",
    "# TensorFlow에서 제공하는 tf.distribute.Strategy를 사용하는 부분이다.\n",
    "# 이는 분산훈련을 지원하는 Tensorflow의 API로 여러 GPU 또는 여러 장치 간에 모델을 효율적으로 분산시켜 학습할 수 있게 한다.\n",
    "# strategy.scope() 내에서 정의된 모델과 연산은 지정된 분산 전략을 따른다. 이렇게 하면 모델이 여러 장치에서 효율적으로 실행된다.\n",
    "with strategy.scope() :\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(len(word_index) + 1, 300, input_length = max_len))\n",
    "    model.add(SimpleRNN(100))\n",
    "    model.add(Dense(1, activation = \"sigmoid\"))\n",
    "    model.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbedf01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "150/150 [==============================] - 178s 1s/step - loss: 0.2853 - accuracy: 0.9083\n",
      "Epoch 2/5\n",
      "150/150 [==============================] - 218s 1s/step - loss: 0.1105 - accuracy: 0.9611\n",
      "Epoch 3/5\n",
      " 60/150 [===========>..................] - ETA: 2:14 - loss: 0.0716 - accuracy: 0.9758"
     ]
    }
   ],
   "source": [
    "model.fit(xtrain_pad, ytrain, epochs = 5, batch_size = 64 * strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c69d22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.predict(xvalid_pad)\n",
    "print(\"Auc : %.2f%%\" % (roc_auc(scores, yvalid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd4a45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_model = []\n",
    "scores_model.append({\"Model\" : \"SimpleRNN\", \"AUC_Score\" : roc_auc(scores, yvalid)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1ad026",
   "metadata": {},
   "source": [
    "## Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e92cef9",
   "metadata": {},
   "source": [
    "Simple RNN을 만들 때 단어 임베딩 사용에 관한 이야기를 했다. 단어 임베딩을 얻기 위한 가장 최근의 접근법은 사전훈련된 GLoVe 또는 FastText를 사용하는 것이다. 이 노트북에서 GloVe를 사용할 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ed47bf",
   "metadata": {},
   "source": [
    "자세한 설명은 해당 노트북에서 전부 링크로 대체해서 필사는 생략하겠다.\n",
    "END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5734a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
